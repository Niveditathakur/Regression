{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regression_MLP_1-D_CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niveditathakur/Regression/blob/master/regression_MLP_1_D_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9jsEE6QAp_BX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import statsmodels.api as sm\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import model_selection, preprocessing, decomposition\n",
        "from sklearn.utils import shuffle\n",
        "from matplotlib.patches import Ellipse\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder,  StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import accuracy_score, log_loss, classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from keras.utils import np_utils\n",
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "seed = 7\n",
        "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv1D, BatchNormalization, MaxPooling1D, Activation, Dropout, Flatten\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BF-V-HtkqrJH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "from sklearn.datasets import load_boston\n",
        "boston_data = load_boston()\n",
        "\n",
        "print('Boston Data Input Shape:', boston_data.data.shape)\n",
        "print('Boston Data Target Shape:', boston_data.target.shape)\n",
        "print('Boston Data Feature Names:', boston_data.feature_names)\n",
        "\n",
        "# Following line will print the detailed description of the data\n",
        "#print('Feature Description:', boston_dataset.DESCR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WCCsN46HquaJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert the input boston data feature into a pandas dataframe with columns as features\n",
        "#print( boston.head(3) )\n",
        "boston = pd.DataFrame(boston_data.data, columns=boston_data.feature_names)\n",
        "print( boston.head(3) )\n",
        "\n",
        "#plot histogram of input featues to see if feature scaling is required\n",
        "boston.hist()\n",
        "plt.show()\n",
        "\n",
        "#we can check if there is a null value - this dataset has none\n",
        "#boston.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_fOkZRxGq5Z_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "boston['Price'] = boston_data.target\n",
        "#derive data and labels\n",
        "data   = boston.drop('Price', axis = 1)  \n",
        "labels = boston['Price']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sy4-1iy3qB_H",
        "colab_type": "code",
        "outputId": "a89e9f56-2fb9-47ed-9a5a-be2603f8b0e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Use a simple MLP for the Regression task\n",
        "# epochs and batch size \n",
        "num_folds = 3 \n",
        "#err_range = 5\n",
        "num_epochs = 100\n",
        "batch_size = 5 \n",
        "\n",
        "def base_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(16, input_dim=data.shape[1], init = 'normal', activation='relu'))\n",
        "    model.add(Dropout(0.2)) # dropout\n",
        "    model.add(Dense(32, init = 'normal', activation='relu'))\n",
        "    model.add(Dropout(0.2)) \n",
        "    #we will not use softmax here as not a classification task\n",
        "    model.add(Dense(1, init='normal'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "    return model\n",
        "\n",
        "reg         =  KerasRegressor(build_fn=base_model, epochs = num_epochs, batch_size = batch_size, verbose=0)\n",
        "kfold       =  KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
        "\n",
        "results     = cross_val_score(reg, data, labels, cv=kfold)\n",
        "print(\"Results RMSE with confidence interval: %.2f (%.2f)\" % (np.sqrt(np.abs(results.mean())), np.sqrt(np.abs(results.std()))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results RMSE with confidence interval: 5.95 (1.85)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gkoKjWZ7spdO",
        "colab_type": "code",
        "outputId": "b2bf152e-b677-4224-f72e-2bf584283a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Employ 1-D CNN for regression \n",
        "def base_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(16, input_shape=(data.shape[1],1), kernel_size=5, strides=2, padding='valid'))\n",
        "    model.add(BatchNormalization()), # batch normalization\n",
        "    model.add(MaxPooling1D(3)), \n",
        "    model.add(Activation('relu')),\n",
        "    model.add(Dropout(0.1)),\n",
        "    model.add(Flatten()),\n",
        "    model.add(Dense(16, init = 'normal', activation='relu'))\n",
        "    model.add(Dropout(0.1)) \n",
        "    #we will not use softmax here as not a classification task\n",
        "    model.add(Dense(1, init='normal'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "    return model\n",
        "  \n",
        "reg         =  KerasRegressor(build_fn=base_model, epochs = num_epochs, batch_size = batch_size, verbose=0)\n",
        "kfold       =  KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
        "\n",
        "#reshape input data for the input of CNN\n",
        "\n",
        "data_cnn    = data.values.reshape(data.shape[0],  data.shape[1],  1) \n",
        "\n",
        "results     = cross_val_score(reg, data_cnn, labels, cv=kfold)\n",
        "\n",
        "print(\"Results RMSE with confidence interval: %.2f (%.2f)\" % (np.sqrt(np.abs(results.mean())), np.sqrt(np.abs(results.std()))))\n",
        "\n",
        "#1D CNN is performing worst in this case as compared to MLP"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results RMSE with confidence interval: 7.81 (2.64)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}